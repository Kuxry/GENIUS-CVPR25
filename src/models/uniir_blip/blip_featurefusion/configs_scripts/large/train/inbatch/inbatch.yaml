data_config:
  enable_query_instruct: true
  hard_neg_num: 0
  image_size: 224, 224
  in_batch_neg_num: 0
  query_instruct_path: instructions/query_instructions.tsv
  returns:
    hashed_p_did: true
  shuffle_cand: true
  train_cand_pool_path: cand_pool/global/mbeir_union_train_cand_pool.jsonl
  train_query_data_path: query/union_train/mbeir_union_up_train.jsonl
  val_cand_pool_path: cand_pool/global/mbeir_union_val_cand_pool.jsonl
  val_query_data_path: query/union_val/mbeir_union_val.jsonl
dataloader_config:
  num_workers: 5
  train_batch_size: 23
  valid_batch_size: 1035
dist_config:
  dist_url: env://
evaluator:
  enable_eval: false
  eval_freq: 1
  print_freq: 10
experiment:
  description: ${model.name} ${model.size} ${experiment.instruct_status} ${experiment.exp_name}
  exp_name: InBatch
  instruct_status: Instruct
  path_suffix: ${model.short_name}/${model.size}/${experiment.instruct_status}/${experiment.exp_name}/
logger_config:
  logger_out_dir: logger/${experiment.path_suffix}
  logger_out_file_name: train.log
model:
  alpha: 0.4
  ckpt_config:
    ckpt_dir: checkpoint/${experiment.path_suffix}
    ckpt_name: ''
    pretrained_blip_url: https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large.pth
    resume_training: false
  embed_dim: 768
  image_size: 224
  name: BLIPFeatureFusion
  queue_size: 57960
  short_name: BLIP_FF
  size: Large
  tokenizer_max_length: 100
  vit: large
  vit_ckpt_layer: 12
  vit_grad_ckpt: true
seed: 2023
trainer_config:
  gradient_accumulation_steps: 1
  init_lr: 1e-5
  num_train_epochs: 20
  print_freq: 50
  weight_decay: 0.05
wandb_config:
  enabled: false
  experiment_name: ${experiment.description}
